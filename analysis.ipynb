{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a1a2598",
   "metadata": {},
   "source": [
    "1)  Business Problem\n",
    "\n",
    "IÂ´m a Data Scientist in a company called House Rockets. This company buy properties to resell. My objective is to help the CEO better understand the business: he needs to find properties being sold at a low price, in a good region, with high resale potential; reform and sell those at a higher price.\n",
    "The CEO have some business questions:\n",
    "1- What is the date of the oldest property in the portfolio?\n",
    "2- How many properties have the maximum number of floors?\n",
    "3- Create a classification for the properties that separate them into low and high standards (according to the price: High standard > $540.000 and Low standard < $540.000).\n",
    "4- Produce a report, ordered by the price and with the following information: id, date when the property stayed available, number of rooms, terrain size, price, property classification\n",
    "5- Produce a map indicating where those properties are located geographically\n",
    "(...)\n",
    "\n",
    "2)  Planning the solution\n",
    "\n",
    "2.1 Planning the final product \n",
    "-Email with attachments:\n",
    "    First, the e-mail text will contain the Questions and Answers that he required    \n",
    "Attachment 1: A .csv file with the new requested information.\n",
    "Annex 2: Maps with the required filters\n",
    "Annex 3: Dashboard with the required filters\n",
    "\n",
    "    \n",
    "2.2 Planning the process\n",
    "\n",
    "1- What is the date of the oldest property in the portfolio?\n",
    "    --Order the dataset by date (minor date to major)\n",
    "    \n",
    "2- How many properties have the maximum number of floors?\n",
    "    --Order the dataset by number of floors (the largest number to smallest)\n",
    "    --Count the number of floors with the bigger number finded \n",
    "    \n",
    "3- Create a classification for the properties that separate them into low and high standards (according to the price: High standard > $540.000 and Low standard < $540.000 ).\n",
    "    --Create a new column in the dataset named 'standard'\n",
    "    --In which line, compare the column 'price'\n",
    "    --If 'price' is bigger than 540.000, I write \"high_standard\", if not I write \"low_standard\"\n",
    "    \n",
    "4- Produce a report, ordered by the price and with the following information: id, date when the property stayed available, number of rooms, terrain size, price, property classification\n",
    "    --Select the columns that I need or delet the ones I do not need\n",
    "\n",
    "5- Produce a map indicating where those properties are located geographically\n",
    "    --Find the library in Python that contains the function that draws maps and learn how to do this \n",
    "\n",
    "6- Create a new column named \"house_age\" with the following values:\n",
    "    --If the date in the column 'date' is superior to 2014-01-01 the classification is 'new_house'\n",
    "    --If the date in the column 'date' is smaller than 2014-01-01 the classification is 'old_ house'\n",
    "    \n",
    "7- Create a new column named 'dormitory_type'with the following values:\n",
    "    --If the value from column 'bedrooms' is equal to 1 the classification is 'studio'\n",
    "    --If the value from column 'bedrooms' is equal to 2 the classification is 'apartment'\n",
    "    --If the value from column 'bedrooms' is bigger than 2 the classification is 'house'\n",
    "    \n",
    "8- Create a new column named 'condition_type' \n",
    "    --If the value from column 'condition' is less than or equal to 2 the classification is 'bad'\n",
    "    --If the value from column 'condition' is equal to 3 or 4 the classification is 'regular'\n",
    "    --If the value from column 'condition' is equal to 5 the classification is 'good'\n",
    "    \n",
    "9- Modify the type of 'condition' column to String.\n",
    "\n",
    "10- Delete the 'sqft_living15' and 'sqft_lot15' columns.\n",
    "\n",
    "11- Modify the type of 'yr_built' column to Date.\n",
    "\n",
    "12- Modify the type of 'yr_renovated' column to Date.\n",
    "\n",
    "13- Which are the eldest construction date of a property?\n",
    "\n",
    "14- Which are the eldest renovation date of a property?\n",
    "\n",
    "15- How many properties have 2 floors?\n",
    "\n",
    "16- How many properties have the 'regular' condition?\n",
    "\n",
    "17- How many properties have 'bad' condition and 'waterfront'?\n",
    "\n",
    "18- How many properties have 'good' condition and are 'new_house'?\n",
    "\n",
    "19- Which is the price of the most expansive property that is a 'studio' type?\n",
    "\n",
    "20- How many properties in type 'apartment' were reformed in 2015?\n",
    "\n",
    "21- Which are the bigger number of bedrooms that a property 'house' type posses?\n",
    "\n",
    "22- How many properties 'new_house' were reformed in 2014?\n",
    "\n",
    "23- Select the columns: 'id', 'date', 'price', 'floors', 'zipcode' from the method:\n",
    "    1. Directly by the names of the columns \n",
    "    2. By the index\n",
    "    3. By yhe index of lines and columns names\n",
    "    4. By boolean index\n",
    "\n",
    "24- Save a .cvs archive with only the columns in the 16 to 23 items.\n",
    "\n",
    "25- What is the number of properties per year of construction?\n",
    "    --Count the number of 'id's' by construction year\n",
    "\n",
    "26- What is the lowest number of rooms per year of building construction?\n",
    "    --Filter all the properties by construction year and select the lowest number of rooms. \n",
    "    \n",
    "27- What is the highest purchase price for each room number?\n",
    "    --Filter all the properties by the number of rooms and select the highest purchase price. \n",
    "    \n",
    "28- What is the sum of all purchase prices per number of rooms?\n",
    "    --Filter all the properties by the number of rooms and sum purchase prices.\n",
    "\n",
    "29- What is the sum of all purchase prices by number of bedrooms and bathrooms?\n",
    "    --Filter all the properties by the number of rooms and bedrooms and sum all purchase prices.\n",
    "    \n",
    "30- What is the average size of real estate rooms per year of construction?\n",
    "    --Filter all the properties by year of construction and calculate the average size of real estate rooms.\n",
    "    \n",
    "31- What is the median size of real estate rooms per year of construction?\n",
    "    --Filter all the properties by year of construction and calculate the average size of real estate rooms.\n",
    "\n",
    "32- What is the standard deviation of the room size of the properties per year of construction?\n",
    "    --Filter all the properties by year of construction and calculate the standard deviation of room size.\n",
    "    \n",
    "33- How is the average growth of real estate purchase prices, by year, by day, and by theweek of the year?\n",
    "    --Filter all the properties by year and make a chart where on the x-axis I put the year and on the y-axis I put the median purchase prices. I repeat this chart for day and week. \n",
    "    --Study some libraries and packages that have a function for drawing a line chart.\n",
    "\n",
    "34- I would like to look at the map and be able to identify the houses with the highest price.\n",
    "    --Modify the map that were made in the other question in a way that the point have their sizes proportional to the price. \n",
    "\n",
    "35- Create a new column called \"dormitory_type\"\n",
    "-If the value of the \"bedrooms\" column is equal to 1 - 'studio'\n",
    "-If the value of the 'bedrooms' column is equal to 2 - 'apartment'\n",
    "-If the value of column \"bedrooms\" is greater than 2 - 'house'\n",
    "\n",
    "36- I would like a bar chart (chart 1) that represents the sum of prices by the number of rooms.\n",
    "\n",
    "37- I would like a line chart (chart 2) that represents the average of prices for the year of construction of the properties.\n",
    "\n",
    "38- I would like a bar chart (chart 3) that represents the average of prices by type of dorms.\n",
    "\n",
    "39- I would like a line chart (chart 4) that shows the evolution of the average of prices for the year of renovation, from the year 1930.\n",
    "\n",
    "40- I would like a table that shows the average prices by year of construction and type of dorms of properties.\n",
    "\n",
    "41- Create a Dashboard with Charts 1, 2 and 3 (Dashboard: 1 row and 2 columns).\n",
    "\n",
    "42- Create a Dashboard with Charts 1 and 3 (Dashboard: 2 columns).\n",
    "\n",
    "43- Create a Dashboard with Charts 2 and 4 (Dashboard: 2 lines).\n",
    "\n",
    "44- I would like a chart with the size of the dots being equal to the size of the living room.\n",
    "\n",
    "45- How many properties per level?\n",
    "-Level 0: Price between $0.00 and $321,950\n",
    "-Level 1: Price between $321,950 and $450,000\n",
    "-Level 2: Price between $450,000 and $645,000\n",
    "-Level 3: Price over $645,000\n",
    "    --Populate the new \"Level\" column with the values conditioned to the requested ranges.\n",
    "    \n",
    "46- Add the following information to the property:\n",
    "-Name of the street\n",
    "-Property number\n",
    "-Name of the Neighborhood\n",
    "-Name of the city\n",
    "-State name\n",
    "    --Where will I find this information? Company database? A spreadsheet? Is it data provided by an API?\n",
    "    --What data do I have in my database that I can make the conection?\n",
    "    --How to collect this data and append it to the original dataset? \n",
    "    \n",
    "47- Add the property level as a color.\n",
    "    --Add the \"Level\" column as a map color.\n",
    "\n",
    "48- Add the property price as the map point size.\n",
    "    --Add the \"Price\" column as a map point.\n",
    "    \n",
    "49- Add filter options for me to do my own analysis:\n",
    "1. I want to choose to view properties with water views or not.\n",
    "2. I want to choose to filter properties up to a certain price value.\n",
    "    --Find a library that has functions that allow you to put filters in Jupyter Notebooks.\n",
    "    --Understand how the library works and add it to Jupyter Notebook.\n",
    "    \n",
    "50- Add filter options in the last uploaded Dashboard:\n",
    "1. I only want to view the values from an available date to purchase the propertie.\n",
    "\n",
    "51- What is the average purchase price of properties by \"Level\"?\n",
    "\n",
    "52- What is the average size of the living room of the properties by \"Size\"?\n",
    "   -Size 0->Size from 0 to 1427 sqft\n",
    "   -Size 1-> Size from 1427 to 1910 sqft\n",
    "   -Size 2-> Size from 1910 to 2550 sqft\n",
    "   -Size 3->Size above 2550 sqft\n",
    "\n",
    "53-Add the following information to the original dataset:\n",
    "   -Place ID: Location identification\n",
    "   -OSM Type: Open Street Map Type\n",
    "   -Country: Country Name\n",
    "   -Country Code: Country code\n",
    "\n",
    "54- Add the following filters to the Map:\n",
    "   -Minimum size of the living room area\n",
    "   -Minimum number of bathrooms\n",
    "   -Maximum Price Value\n",
    "   -Maximum size of basement area\n",
    "   -Filter of Property Conditions\n",
    "   -Filter by Year of Construction\n",
    "\n",
    "55- Add the following filters to the Dashboard:\n",
    "   -Filter by date available for purchase\n",
    "   -Filter by year of renewal\n",
    "   -Filter if it has water view or not\n",
    "\n",
    "2.3 Planning the tools that will be used \n",
    "-Which tools do I have available? Excel, Python, R\n",
    "-Which tools I will use? Python 3.8.0, PyCharm and Jupyter Notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682784d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:36:56.988056Z",
     "start_time": "2023-05-17T16:36:56.425496Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b64c52a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:05.658185Z",
     "start_time": "2023-05-17T16:37:05.565161Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "data = pd.read_csv ( 'datasets/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e88c6cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:08.712555Z",
     "start_time": "2023-05-17T16:37:08.660557Z"
    }
   },
   "outputs": [],
   "source": [
    "#1- What is the date of the oldest property in the portfolio? - strategy: order the dataset by date (minor date to major)\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "print(data.sort_values('date', ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5d031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:25.982677Z",
     "start_time": "2023-05-17T16:37:25.955671Z"
    }
   },
   "outputs": [],
   "source": [
    "#2- How many properties have the maximum number of floors? -strategy: order the dataset by number of floors (the largest number\n",
    "#to smallest) and count the number of floors with the bigger number finded \n",
    "print(data['floors'].unique())\n",
    "print(data[ data['floors'] == 3.5][['floors', 'id']])\n",
    "print(data[data['floors'] == 3.5].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ffcc21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:27.076068Z",
     "start_time": "2023-05-17T16:37:27.055066Z"
    }
   },
   "outputs": [],
   "source": [
    "#3- Create a classification for the properties that separate them into low and high standards (according to the price: High standard > $540.000 and Low standard < $540.000 ).\n",
    "    #strategy: Create a new column in the dataset named 'standard'\n",
    "    #--In which line, compare the column 'price'\n",
    "    #--If 'price' is bigger than 540.000, I write \"high_standard\", if not I write \"low_standard\"\n",
    "    \n",
    "data['standard'] = 'standard'\n",
    "data.loc[data['price'] > 540000, 'standard'] = 'high_standard'\n",
    "data.loc[data['price'] < 540000, 'standard'] = 'low_standard'\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d627a3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:28.396167Z",
     "start_time": "2023-05-17T16:37:28.269139Z"
    }
   },
   "outputs": [],
   "source": [
    "#4- Produce a report, ordered by the price and with the following information: id, date when the property stayed available, \n",
    "#number of rooms, terrain size, price, property classification - strategy: select the columns that I need or delet the ones \n",
    "#I do not need for the report\n",
    "\n",
    "report = data[['id', 'date', 'price', 'bedrooms', 'sqft_lot', 'standard']].sort_values('price', ascending=False)\n",
    "print(report)\n",
    "#then, I save in a .csv document\n",
    "report.to_csv('datasets/report_aula02.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57a37a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:37.520084Z",
     "start_time": "2023-05-17T16:37:35.192825Z"
    }
   },
   "outputs": [],
   "source": [
    "#5- Produce a map indicating where those properties are located geographically\n",
    "#strategy:Find the library in Python that contains the function that draws maps and learn how to do this \n",
    "#plotly is the library that have the function to draw maps: scatter MapBox\n",
    "import plotly.express as px\n",
    "data_map = data[['id', 'lat', 'long', 'price']]\n",
    "map = px.scatter_mapbox (data_map, lat='lat' , lon='long' , hover_name='id' , hover_data=['price'],\n",
    "                color_discrete_sequence= ['fuchsia'], zoom=3, height=300)\n",
    "map.update_layout(mapbox_style='open-street-map')\n",
    "map.update_layout(height=600, margin={'r':0, 't':0, 'l':0, 'b':0 })\n",
    "map.show()\n",
    "map.write_html('datasets/mapa_house_rocket.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdebc781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:40.963290Z",
     "start_time": "2023-05-17T16:37:37.522080Z"
    }
   },
   "outputs": [],
   "source": [
    "#6- Create a new column named \"house_age\" with the following values:\n",
    "   # --If the date in the column 'date' is superior to 2014-01-01 the classification is 'new_house'\n",
    "   # --If the date in the column 'date' is smaller than 2014-01-01 the classification is 'old_ house'\n",
    "data['date'] = pd.to_datetime( data['date'], format='%Y-%m-%d')  \n",
    "data['house_age'] = data['date'].apply(lambda x: 'new_house' if x> pd.to_datetime( '2014-01-01', format='%Y-%m-%d') else 'old_house') \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42afde5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:41.011294Z",
     "start_time": "2023-05-17T16:37:40.967289Z"
    }
   },
   "outputs": [],
   "source": [
    "#7- Create a new column named 'dormitory_type'with the following values:\n",
    "   # --If the value from column 'bedrooms' is equal to 1 the classification is 'studio'\n",
    "   # --If the value from column 'bedrooms' is equal to 2 the classification is 'apartment'\n",
    "   # --If the value from column 'bedrooms' is bigger than 2 the classification is 'house'\n",
    "data['dormitory_type'] = data['bedrooms'].apply( lambda x: 'studio' if x == 1 else \n",
    "                                                           'apartment' if x == 2 else\n",
    "                                                           'house' if x > 2 else\n",
    "                                                           'NA') \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf60abf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:41.059289Z",
     "start_time": "2023-05-17T16:37:41.014290Z"
    }
   },
   "outputs": [],
   "source": [
    "#8- Create a new column named 'condition_type' \n",
    "   # --If the value from column 'condition' is less than or equal to 2 the classification is 'bad'\n",
    "   # --If the value from column 'condition' is equal to 3 or 4 the classification is 'regular'\n",
    "   # --If the value from column 'condition' is equal to 5 the classification is 'good'\n",
    "    \n",
    "data['condition_type'] = data['condition'].apply( lambda x: 'bad' if x <= 2  else \n",
    "                                                           'regular' if (x==3) | (x==4)  else 'good') \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d25ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:41.091290Z",
     "start_time": "2023-05-17T16:37:41.062290Z"
    }
   },
   "outputs": [],
   "source": [
    "#9- Modify the type of 'condition' column to String.\n",
    "\n",
    "data['condition'] = data['condition'].astype(str)\n",
    "data.dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd6c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:41.139295Z",
     "start_time": "2023-05-17T16:37:41.096291Z"
    }
   },
   "outputs": [],
   "source": [
    "#10- Delete the 'sqft_living15' and 'sqft_lot15' columns.\n",
    "\n",
    "data = data.drop(['sqft_living15', 'sqft_lot15'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901522e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:41.171289Z",
     "start_time": "2023-05-17T16:37:41.144300Z"
    }
   },
   "outputs": [],
   "source": [
    "#11- Modify the type of 'yr_built' column to Date.\n",
    "data['yr_built'] = pd.to_datetime(data['yr_built'], format='%Y')\n",
    "data['yr_built']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664219a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:44.828050Z",
     "start_time": "2023-05-17T16:37:41.174292Z"
    }
   },
   "outputs": [],
   "source": [
    "#12- Modify the type of 'yr_renovated' column to Date.\n",
    "data['yr_renovated'] = data['yr_renovated'].apply(lambda x: pd.to_datetime('1900-01-01', format='%Y-%m-%d') if x == 0\n",
    "                                                  else pd.to_datetime(x, format='%Y'))\n",
    "data['yr_renovated']\n",
    "#some values are 0, which means that I did not have any renovation on those properties,\n",
    "# so I decided to put zeros as 1900-01-01 to maintain the Date type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c202e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:44.843056Z",
     "start_time": "2023-05-17T16:37:44.831055Z"
    }
   },
   "outputs": [],
   "source": [
    "#13- Which are the eldest construction date of a property?\n",
    "data['yr_built'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef77eb53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:44.858094Z",
     "start_time": "2023-05-17T16:37:44.845054Z"
    }
   },
   "outputs": [],
   "source": [
    "#14- Which are the eldest renovation date of a property? - strategy: First, I have to select all the columns that are not the\n",
    "# zeros - that I transformed in 1900-01-01. Then I search for the eldest date\n",
    "data.loc[data['yr_renovated'] > pd.to_datetime('1900-01-01', format='%Y-%m-%d'), 'yr_renovated'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf57cfce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:44.874091Z",
     "start_time": "2023-05-17T16:37:44.860057Z"
    }
   },
   "outputs": [],
   "source": [
    "#15- How many properties have 2 floors?\n",
    "data.loc[data['floors'] == 2, 'id'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b230a13d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:44.890096Z",
     "start_time": "2023-05-17T16:37:44.876055Z"
    }
   },
   "outputs": [],
   "source": [
    "#16- How many properties have the 'regular' condition?\n",
    "data.loc[data['condition_type'] == 'regular', 'id'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c161f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:44.906093Z",
     "start_time": "2023-05-17T16:37:44.892056Z"
    }
   },
   "outputs": [],
   "source": [
    "#17- How many properties have 'bad' condition and 'waterfront'?\n",
    "data.loc[(data['condition_type'] == 'bad') & (data['waterfront'] == 1), 'id'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85aa4cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:45.080605Z",
     "start_time": "2023-05-17T16:37:45.054609Z"
    }
   },
   "outputs": [],
   "source": [
    "#18- How many properties have 'good' condition and are 'new_house'?\n",
    "data.loc[(data['condition_type'] == 'good') & (data['house_age'] == 'new_house'), 'id'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5aad4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:45.176151Z",
     "start_time": "2023-05-17T16:37:45.150146Z"
    }
   },
   "outputs": [],
   "source": [
    "#19- Which is the price of the most expansive property that is a 'studio' type?\n",
    "data.loc[data['dormitory_type'] == 'studio', 'price'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74096eb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:46.885905Z",
     "start_time": "2023-05-17T16:37:46.864911Z"
    }
   },
   "outputs": [],
   "source": [
    "#20- How many properties in type 'apartment' were reformed in 2015?\n",
    "data.loc[(data['dormitory_type'] == 'apartment') & (data['yr_renovated'] == '2015-01-01'), 'id'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa554f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:47.635926Z",
     "start_time": "2023-05-17T16:37:47.616897Z"
    }
   },
   "outputs": [],
   "source": [
    "#21- Which are the bigger number of bedrooms that a property 'house' type posses?\n",
    "data.loc[data['dormitory_type'] == 'house', 'bedrooms'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4020e621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:48.531620Z",
     "start_time": "2023-05-17T16:37:48.510624Z"
    }
   },
   "outputs": [],
   "source": [
    "#22- How many properties 'new_house' were reformed in 2014?\n",
    "data.loc[( data['house_age'] == 'new_house') & \n",
    "         ( data['yr_renovated'] == pd.to_datetime('2014-01-01', format='%Y-%m-%d' )), 'id'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c39ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:50.188001Z",
     "start_time": "2023-05-17T16:37:50.167000Z"
    }
   },
   "outputs": [],
   "source": [
    "#23- Select the columns: 'id', 'date', 'price', 'floors', 'zipcode' from the method:\n",
    "   # 1. Directly by the columns names\n",
    "#data [['id', 'date', 'price','floors', 'zipcode']]    \n",
    "   # 2. By the index\n",
    "#data.iloc[:,[0,1,2,7,16]]    \n",
    "   # 3. By yhe index of lines and columns names\n",
    "#data.iloc[0:10, [0,1,2,7,16]]\n",
    "   # 4. By boolean index\n",
    "data.iloc[0:10, [True, True, True, False, False, False, False, True, False, False, False, \n",
    "                 False, False, False, False, False, True, False, False, False, False, False, False] ]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaef85a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:51.143502Z",
     "start_time": "2023-05-17T16:37:51.069396Z"
    }
   },
   "outputs": [],
   "source": [
    "#24- Save a .cvs archive with only the columns created in 6 to 8 items.\n",
    "data[['house_age', 'dormitory_type', 'condition_type']].to_csv('exercicio_19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a95f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:51.860744Z",
     "start_time": "2023-05-17T16:37:51.844702Z"
    }
   },
   "outputs": [],
   "source": [
    "#25- What is the number of properties per year of construction?\n",
    "data[['id', 'yr_built']].groupby('yr_built').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27deaf9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:52.582996Z",
     "start_time": "2023-05-17T16:37:52.555997Z"
    }
   },
   "outputs": [],
   "source": [
    "#26- What is the lowest number of rooms per year of building construction?\n",
    "data[['bedrooms', 'yr_built']].groupby('yr_built').min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151bcdb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:53.319841Z",
     "start_time": "2023-05-17T16:37:53.296837Z"
    }
   },
   "outputs": [],
   "source": [
    "#27- What is the highest purchase price for each room number?\n",
    "data[['price', 'bedrooms']].groupby('bedrooms').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37391727",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:53.993567Z",
     "start_time": "2023-05-17T16:37:53.967500Z"
    }
   },
   "outputs": [],
   "source": [
    "#28- What is the sum of all purchase prices per number of rooms?\n",
    "data[['price', 'bedrooms']].groupby('bedrooms').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1c6ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:54.730639Z",
     "start_time": "2023-05-17T16:37:54.699602Z"
    }
   },
   "outputs": [],
   "source": [
    "#29- What is the sum of all purchase prices by number of bedrooms and bathrooms?\n",
    "data[['price', 'bedrooms', 'bathrooms']].groupby(['bedrooms', 'bathrooms']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e995a93a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:55.880399Z",
     "start_time": "2023-05-17T16:37:55.862402Z"
    }
   },
   "outputs": [],
   "source": [
    "#30- What is the average size of real estate rooms per year of construction?\n",
    "data[['sqft_living', 'yr_built']].groupby('yr_built').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7cd7ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:56.827710Z",
     "start_time": "2023-05-17T16:37:56.803663Z"
    }
   },
   "outputs": [],
   "source": [
    "#31- What is the median size of real estate rooms per year of construction?\n",
    "data[['sqft_living', 'yr_built']].groupby('yr_built').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96211ee7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:57.699432Z",
     "start_time": "2023-05-17T16:37:57.674433Z"
    }
   },
   "outputs": [],
   "source": [
    "#32- What is the standard deviation of the room size of the properties per year of construction?\n",
    "data[['sqft_living', 'yr_built']].groupby('yr_built').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab868ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:37:59.439581Z",
     "start_time": "2023-05-17T16:37:58.493468Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#33- How is the average growth of real estate purchase prices, by year, by day and by week of the year?\n",
    "#By year\n",
    "#First I need to create a column year separated from the date column. \n",
    "data['year']= pd.to_datetime(data['date']).dt.year\n",
    "from matplotlib import pyplot as plt\n",
    "by_year = data[['price', 'year']].groupby('year').mean().reset_index()\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.bar(by_year['year'], by_year['price'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c9552",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:00.805532Z",
     "start_time": "2023-05-17T16:38:00.424492Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#By day\n",
    "#First I need to create a column year separated from the date column. \n",
    "data['day']= pd.to_datetime(data['date'])\n",
    "by_day = data[['price', 'day']].groupby('day').mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.plot(by_day['day'], by_day['price'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627d024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:02.784581Z",
     "start_time": "2023-05-17T16:38:02.017205Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#By week\n",
    "#First I need to create a column year separated from the date column. \n",
    "data['year_week']= pd.to_datetime(data['date']).dt.strftime('%Y-%U')\n",
    "by_year_week = data[['price', 'year_week']].groupby('year_week').mean().reset_index()\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.plot(by_year_week['year_week'], by_year_week['price'] )\n",
    "plt.xticks(rotation=60);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce829187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:05.053532Z",
     "start_time": "2023-05-17T16:38:03.879669Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "\n",
    "fig = plt. figure(figsize=(20, 12))\n",
    "specs = gridspec.GridSpec(ncols=2, nrows=2, figure=fig)\n",
    "\n",
    "ax1 = fig.add_subplot(specs[0, :])\n",
    "ax2 = fig.add_subplot(specs[1, 0])\n",
    "ax3 = fig.add_subplot(specs[1, 1])\n",
    "\n",
    "\n",
    "#By year\n",
    "#First I need to create a column year separated from the date column. \n",
    "data['year']= pd.to_datetime(data['date']).dt.year\n",
    "from matplotlib import pyplot as plt\n",
    "by_year = data[['price', 'year']].groupby('year').sum().reset_index()\n",
    "ax1.bar(by_year['year'], by_year['price'] )\n",
    "\n",
    "#By day\n",
    "#First I need to create a column day separated from the date column. \n",
    "data['day']= pd.to_datetime(data['date'])\n",
    "by_day = data[['price', 'day']].groupby('day').mean().reset_index()\n",
    "ax2.plot(by_day['day'], by_day['price'] )\n",
    "\n",
    "#By week\n",
    "#First I need to create a column week separated from the date column. \n",
    "data['year_week']= pd.to_datetime(data['date']).dt.strftime('%Y-%U')\n",
    "by_year_week = data[['price', 'year_week']].groupby('year_week').mean().reset_index()\n",
    "ax3.plot(by_year_week['year_week'], by_year_week['price'] )\n",
    "plt.xticks(rotation=60);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abbeffb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:05.654244Z",
     "start_time": "2023-05-17T16:38:05.387879Z"
    }
   },
   "outputs": [],
   "source": [
    "#34- I would like to look at the map and be able to identify the houses with the highest price.\n",
    "\n",
    "house = data[['id', 'lat', 'long', 'price']]\n",
    "fig = px.scatter_mapbox (house,\n",
    "                         lat='lat',\n",
    "                         lon='long',\n",
    "                         size= 'price',\n",
    "                         color_continuous_scale=px.colors.cyclical.IceFire,\n",
    "                         size_max=15,\n",
    "                         zoom=10)\n",
    "                \n",
    "fig.update_layout(mapbox_style='open-street-map')\n",
    "fig.update_layout(height=600, margin={'r':0, 't':0, 'l':0, 'b':0 })\n",
    "fig.show()\n",
    "map.write_html('datasets/mapa_house_rocket.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185470ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:07.787259Z",
     "start_time": "2023-05-17T16:38:07.769258Z"
    }
   },
   "outputs": [],
   "source": [
    "#35- Create a new column called \"dormitory_type\"\n",
    "#-If the value of the \"bedrooms\" column is equal to 1 - 'studio'\n",
    "#-If the value of the 'bedrooms' column is equal to 2 - 'apartment'\n",
    "#-If the value of column \"bedrooms\" is greater than 2 - 'house'\n",
    "data['dormitory_type'] = data ['bedrooms'].apply(lambda x: 'studio' if x == 1 else\n",
    "                                                            'apartment' if x == 2 else\n",
    "                                                            'house' if x > 2 else 'NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c2c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:09.617693Z",
     "start_time": "2023-05-17T16:38:08.817733Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "import seaborn as sns\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    plt.style.use ('bmh')\n",
    "    plt.rcParams['figure.figsize'] = [20,6]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    display(HTML('<style>.container {width:100% !important; }</style>'))\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option ('display.expand_frame_repr', False)\n",
    "    sns.set()\n",
    "jupyter_settings() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d285ed53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:13.354811Z",
     "start_time": "2023-05-17T16:38:12.806300Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#36- I would like a bar chart (chart 1) that represents the sum of prices by the number of rooms.\n",
    "df = data[['price', 'bedrooms']].groupby('bedrooms').sum().reset_index()\n",
    "sns.barplot(x='bedrooms', y='price', data = df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100fc30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:15.152343Z",
     "start_time": "2023-05-17T16:38:14.595656Z"
    }
   },
   "outputs": [],
   "source": [
    "#37- I would like a line chart (Chart 2) that represents the average of prices for the year of construction of the properties.\n",
    "df2 = data[['price', 'yr_built']].groupby('yr_built').mean().reset_index()\n",
    "sns.lineplot(x='yr_built', y='price', data = df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fbbe74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:16.775374Z",
     "start_time": "2023-05-17T16:38:16.527334Z"
    }
   },
   "outputs": [],
   "source": [
    "#38- I would like a bar chart (Chart 3) that represents the average of prices by type of dorms.\n",
    "df3 = data[['price', 'dormitory_type']].groupby('dormitory_type').mean().reset_index()\n",
    "sns.barplot(x='dormitory_type', y='price', data = df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1752d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:17.842215Z",
     "start_time": "2023-05-17T16:38:17.680078Z"
    }
   },
   "outputs": [],
   "source": [
    "#39- I would like a line chart (Chart 4) that shows the evolution of the average of prices for the year \n",
    "#of renovation, from the year 1930.\n",
    "data['yr_renovated2']= pd.to_datetime(data['yr_renovated']).dt.year\n",
    "data['yr_renovated2'].head\n",
    "#I put 1900-01-01 as a default for 0, when the house didÂ´n have any renovation, so I will filter for >1930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf3509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:19.759083Z",
     "start_time": "2023-05-17T16:38:19.370445Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df4 = data.loc[data['yr_renovated2'] > 1930, ['price', 'yr_renovated2']].groupby('yr_renovated2').mean().reset_index()\n",
    "\n",
    "sns.lineplot(x='yr_renovated2', y='price', data = df4)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac22efa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:20.229495Z",
     "start_time": "2023-05-17T16:38:20.206495Z"
    }
   },
   "outputs": [],
   "source": [
    "#40- I would like a table that shows the average prices by year of construction and type of dorms of properties.\n",
    "\n",
    "df=data[['price' , 'dormitory_type']].groupby('dormitory_type').mean().reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364e2fb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:21.940765Z",
     "start_time": "2023-05-17T16:38:21.068765Z"
    }
   },
   "outputs": [],
   "source": [
    "#41- Create a Dashboard with charts 1, 2 and 3 (Dashboard: 2 rows and 2 columns).\n",
    "from matplotlib import gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(24, 12))\n",
    "soecs = gridspec.GridSpec(ncols= 2, nrows= 2,figure=fig)\n",
    "ax1 = fig.add_subplot ( specs[0, :] ) #first line and two columns\n",
    "ax2 = fig.add_subplot ( specs[1, 0] ) #first line and first column\n",
    "ax3 = fig.add_subplot ( specs[1, 1] ) #second line and second column\n",
    "\n",
    "#Chart 2\n",
    "df2 = data[['price', 'yr_built']].groupby('yr_built').mean().reset_index()\n",
    "ax1.plot(df2['yr_built'], df2['price'])\n",
    "\n",
    "#Chart 1\n",
    "df = data[['price', 'bedrooms']].groupby('bedrooms').sum().reset_index()\n",
    "ax2.bar (df['bedrooms'], df['price'])\n",
    "\n",
    "#Chart 3\n",
    "df3 = data[['price', 'dormitory_type']].groupby('dormitory_type').mean().reset_index()\n",
    "ax3.bar(df3['dormitory_type'], df3['price']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f42a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:22.432502Z",
     "start_time": "2023-05-17T16:38:21.942767Z"
    }
   },
   "outputs": [],
   "source": [
    "#42- Create a Dashboard with charts 1 and 3 (Dashboard: 2 columns).\n",
    "\n",
    "fig = plt.figure(figsize=(24, 12))\n",
    "soecs = gridspec.GridSpec(ncols= 2, nrows= 1,figure=fig)\n",
    "ax2 = fig.add_subplot ( specs[0, 0] ) #first line and first column\n",
    "ax3 = fig.add_subplot ( specs[0, 1] ) #first line and second column\n",
    "\n",
    "#Chart 1\n",
    "df = data[['price', 'bedrooms']].groupby('bedrooms').sum().reset_index()\n",
    "ax2.bar (df['bedrooms'], df['price'])\n",
    "\n",
    "#Chart 3\n",
    "df3 = data[['price', 'dormitory_type']].groupby('dormitory_type').mean().reset_index()\n",
    "ax3.bar(df3['dormitory_type'], df3['price']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fb5d89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:23.361306Z",
     "start_time": "2023-05-17T16:38:22.647121Z"
    }
   },
   "outputs": [],
   "source": [
    "#43- Create a Dashboard with charts 2 and 4 (Dashboard: 2 lines).\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "soecs = gridspec.GridSpec(ncols= 1, nrows= 2,figure=fig)\n",
    "ax1 = fig.add_subplot ( specs[0, 0] ) #first line and first columns\n",
    "ax2 = fig.add_subplot ( specs[1, 0] ) #second line and first column\n",
    "\n",
    "\n",
    "#Chart 2\n",
    "df2 = data[['price', 'yr_built']].groupby('yr_built').mean().reset_index()\n",
    "sns.lineplot(x='yr_built', y='price', data=df2, ax=ax1)\n",
    "\n",
    "#Chart 1\n",
    "df4 = data.loc[data['yr_renovated2'] > 1930, ['price', 'yr_renovated2']].groupby('yr_renovated2').mean().reset_index()\n",
    "ax2.plot(df4['yr_renovated2'], df4['price']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4402d50b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:23.659818Z",
     "start_time": "2023-05-17T16:38:23.501820Z"
    }
   },
   "outputs": [],
   "source": [
    "#44- I would like a chart with the size of the dots being equal to the size of the living room.\n",
    "house = data[['id', 'lat', 'long', 'price', 'sqft_living']].copy()\n",
    "\n",
    "map = px.scatter_mapbox (house, lat='lat', \n",
    "                         lon='long', \n",
    "                         size='sqft_living', \n",
    "                         color_continuous_scale=px.colors.cyclical.IceFire, \n",
    "                         size_max =20, \n",
    "                         zoom =10)\n",
    "                \n",
    "    \n",
    "map.update_layout(mapbox_style='open-street-map')\n",
    "map.update_layout(height=600, margin={'r':0, 't':0, 'l':0, 'b':0 })\n",
    "map.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd82bc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:24.498509Z",
     "start_time": "2023-05-17T16:38:24.452519Z"
    }
   },
   "outputs": [],
   "source": [
    "#45- How many properties per level?\n",
    "#-Level 0: Price between $0.00 and $321,950\n",
    "#-Level 1: Price between $321,950 and $450,000\n",
    "#-Level 2: Price between $450,000 and $645,000\n",
    "#-Level 3: Price over $645,000\n",
    "\n",
    "#Three possibilities to create this column:\n",
    "#First(not very optimized):\n",
    "#data['Level'] = NA\n",
    "#data.loc[data[(data['price'] >= 0) & (data['price'] < 321950)], 'Level'] = 'Level_0'\n",
    "#data.loc[data[(data['price'] >= 321950) & (data['price'] < 450000)], 'Level'] = 'Level_1'\n",
    "#data.loc[data[(data['price'] >= 450000) & (data['price'] < 645000)], 'Level'] = 'Level_2'\n",
    "#data.loc[data[(data['price'] >= 645000)], 'Level'] = 'Level_3'\n",
    "\n",
    "#Second (optimized):\n",
    "#for i in range ( len (data) ):\n",
    "    #if (data.loc[i, 'price'] > 0) & (data.loc[i, 'price'] < 321950):\n",
    "        #data.loc[i, 'Level'] = 'Level_0'\n",
    "    #elif (data.loc[i, 'price'] >= 321950) & (data.loc[i, 'price'] < 450000):\n",
    "        #data.loc[i, 'Level'] = 'Level_1'\n",
    "    #elif (data.loc[i, 'price'] >= 450000) & (data.loc[i, 'price'] < 645000):\n",
    "        #data.loc[i, 'Level'] ='Level_2'\n",
    "    #else: \n",
    "        #data.loc[i, 'Level'] = 'Level_3'\n",
    "\n",
    "#Third (more optimized):\n",
    "data['Level'] = data['price'].apply(lambda x: 'Level_0' if ( x >= 0 ) & ( x <= 321950 ) else\n",
    "                                              'Level_1' if ( x > 321950 ) & ( x <= 450000 ) else\n",
    "                                              'Level_2' if ( x > 450000) & ( x <= 645000) else 'Level_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6034921f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:25.963040Z",
     "start_time": "2023-05-17T16:38:25.272081Z"
    }
   },
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9662ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:26.307709Z",
     "start_time": "2023-05-17T16:38:26.285669Z"
    }
   },
   "outputs": [],
   "source": [
    "#46- Add the following information to the property:\n",
    "#-Name of the street\n",
    "#-Property number\n",
    "#-Name of the Neighborhood\n",
    "#-Name of the city\n",
    "#-State name\n",
    "    #--I have this information in an API. I have zipcode and lat and long coordinates to find the adresses.\n",
    "    \n",
    "#Create empty columns\n",
    "data['road'] = 'NA'\n",
    "data['house_number'] = 'NA'\n",
    "data['neighborhood'] = 'NA'\n",
    "data['city'] = 'NA'\n",
    "data['state'] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04849704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:27.196364Z",
     "start_time": "2023-05-17T16:38:27.169306Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a208a6a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:28.061505Z",
     "start_time": "2023-05-17T16:38:28.023506Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "\n",
    "#Initialize Nominatim API and see in geolocator documentation which data are available.\n",
    "user_agent = 'user_me_{}'.format(randint(10000,99999))\n",
    "geolocator = Nominatim(user_agent=user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6c3d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:28.743168Z",
     "start_time": "2023-05-17T16:38:28.687157Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "\n",
    "     #make query\n",
    "    query = str(data.loc[i, 'lat'])+ ',' + str(data.loc[i, 'long'])\n",
    "     \n",
    "     #API Request \n",
    "    response = geolocator.reverse(query)\n",
    "     \n",
    "     #populate data\n",
    "    if 'road' in response.raw['address']:\n",
    "        data.loc[i,'road']                = response.raw['address']['road']\n",
    "        \n",
    "    if 'house_number' in response.raw['address']:\n",
    "        data.loc[i,'house_number']        = response.raw['address']['house_number']\n",
    "        \n",
    "    if 'neighborhood' in response.raw['address']:\n",
    "        data.loc[i,'neighborhood']        = response.raw['address']['neighborhood']\n",
    "        \n",
    "    if 'city' in response.raw['address']:\n",
    "        data.loc[i,'city']                = response.raw['address']['city']\n",
    "    \n",
    "    if 'state' in response.raw['address']:\n",
    "        data.loc[i,'state']               = response.raw['address']['state']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d5bca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:29.548438Z",
     "start_time": "2023-05-17T16:38:29.533445Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb4ad4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:34.210246Z",
     "start_time": "2023-05-17T16:38:30.292465Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#47- Add the property level as a color.\n",
    "#48- Add the property price as the map point size.\n",
    "\n",
    "houses = data[['id', 'lat', 'long', 'price']].copy()\n",
    "\n",
    "#define prices \n",
    "for i in range ( len (houses) ):\n",
    "    if houses.loc[i, 'price'] <= 321950:\n",
    "        houses.loc[i, 'Level'] = 0\n",
    "    elif (houses.loc[i, 'price'] > 321950) & (houses.loc[i, 'price'] <= 450000):\n",
    "        houses.loc[i, 'Level'] = 1\n",
    "    elif (houses.loc[i, 'price'] > 450000) & (houses.loc[i, 'price'] <= 645000):\n",
    "        houses.loc[i, 'Level'] = 2\n",
    "    else:\n",
    "        houses.loc[i, 'Level'] = 3\n",
    "houses['Level'] = houses['Level']. astype(int)\n",
    "\n",
    "fig=px.scatter_mapbox(houses, \n",
    "                     lat = 'lat',\n",
    "                     lon = 'long',\n",
    "                     color = 'Level',\n",
    "                     size = 'price',\n",
    "                     color_continuous_scale = px.colors.cyclical.IceFire,\n",
    "                     size_max = 15,\n",
    "                     zoom = 10)\n",
    "\n",
    "fig.update_layout( mapbox_style = 'open-street-map' )\n",
    "fig.update_layout( height = 600, margin = {'r':0, 't':0, 'l':0, 'b':0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6454c7cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:34.226262Z",
     "start_time": "2023-05-17T16:38:34.212219Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f56332c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:34.319221Z",
     "start_time": "2023-05-17T16:38:34.229222Z"
    }
   },
   "outputs": [],
   "source": [
    "#49- Add filter options for me to do my own analysis:\n",
    "#1. I want to choose to view properties with water views or not.\n",
    "#2. I want to choose to filter properties up to a certain price value.\n",
    "\n",
    "df= pd.read_csv('datasets/kc_house_data.csv')\n",
    "\n",
    "df['is_waterfront'] = df['waterfront'].apply( lambda x: 'yes' if x == 1 else 'no' )\n",
    "\n",
    "df['Level'] = df['price'].apply( lambda x: 0 if x< 321950 else\n",
    "                                           1 if (x > 321950) & (x < 450000) else\n",
    "                                           2 if (x > 450000) & (x < 645000) else 3 )\n",
    "df['Level'] = df['Level'].astype( int )\n",
    "style = {'description_width': 'initial'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425fe0b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:34.351234Z",
     "start_time": "2023-05-17T16:38:34.322217Z"
    }
   },
   "outputs": [],
   "source": [
    "#Iterative buttons\n",
    "price_limit = widgets.IntSlider(\n",
    "                value = 540000,\n",
    "                min = 75000,\n",
    "                max = 7700000,\n",
    "                step = 1,\n",
    "                description = 'Maximun Price',\n",
    "                disable = False,\n",
    "                style = style\n",
    ")\n",
    "\n",
    "waterfront_bar = widgets.Dropdown(\n",
    "                options=df['is_waterfront'].unique().tolist(),\n",
    "                value='yes',\n",
    "                description='Water View',\n",
    "                disable= False)\n",
    "\n",
    "def update_map(df, waterfront, limit):\n",
    "    houses = df[(df['price'] <= limit) & \n",
    "            (df['is_waterfront'] == waterfront)][['id', 'lat', 'long', 'price', 'Level']]\n",
    "    \n",
    "    fig=px.scatter_mapbox(houses, \n",
    "                     lat = 'lat',\n",
    "                     lon = 'long',\n",
    "                     color = 'Level',\n",
    "                     size = 'price',\n",
    "                     color_continuous_scale = px.colors.cyclical.IceFire,\n",
    "                     size_max = 15,\n",
    "                     zoom = 10)\n",
    "\n",
    "    fig.update_layout( mapbox_style = 'open-street-map' )\n",
    "    fig.update_layout( height = 600, margin = {'r':0, 't':0, 'l':0, 'b':0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b25c66f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:34.634077Z",
     "start_time": "2023-05-17T16:38:34.505076Z"
    }
   },
   "outputs": [],
   "source": [
    "widgets.interactive(update_map, df=fixed(df), waterfront=waterfront_bar, limit=price_limit)                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07fd7d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:35.318245Z",
     "start_time": "2023-05-17T16:38:35.303243Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1be0b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:36.664914Z",
     "start_time": "2023-05-17T16:38:36.285364Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#50- Add filter options in the last uploaded Dashboard:\n",
    "#1. I only want to view values from an available date to purchase.\n",
    "\n",
    "#Preparing dataset\n",
    "data= pd.read_csv('datasets/kc_house_data.csv')\n",
    "\n",
    "#Change date format\n",
    "data['year'] = pd.to_datetime( data['date'] ).dt.strftime( '%Y' )\n",
    "data['date'] = pd.to_datetime( data['date'] ).dt.strftime( '%Y-%m-%d' )\n",
    "data['year_week'] = pd.to_datetime( data['date'] ).dt.strftime( '%Y-%U' )\n",
    "\n",
    "#Widgets to filter data\n",
    "date_limit = widgets.SelectionSlider(\n",
    "    options = data['date'].sort_values().unique().tolist(),\n",
    "    value = '2014-12-01',\n",
    "    description = 'Date',\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True)\n",
    "\n",
    "def update_map(data,limit):\n",
    "    #Filter data\n",
    "    df = data[data['date'] >= limit].copy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(21,12))\n",
    "    specs = gridspec.GridSpec(ncols=2, nrows=2, figure=fig)\n",
    "    \n",
    "    ax1 = fig.add_subplot(specs[0, :]) #First row\n",
    "    ax2 = fig.add_subplot(specs[1, 0]) #Second row First Column\n",
    "    ax3 = fig.add_subplot(specs[1, 1]) #Second row Second Column\n",
    "    \n",
    "    by_year = df[['id', 'year']].groupby('year').sum().reset_index()\n",
    "    ax1.bar(by_year['year'], by_year['id'])\n",
    "    \n",
    "    by_day = df[['id', 'date']].groupby('date').mean().reset_index()\n",
    "    ax2.plot(by_day['date'], by_day['id'])\n",
    "    ax2.set_title('Title: Average Price By Day')\n",
    "    \n",
    "    by_week_of_year = df[['id', 'year_week']].groupby('year_week').mean().reset_index()\n",
    "    ax3.bar(by_week_of_year['year_week'], by_week_of_year['id'])\n",
    "    ax3.set_title('Title: Average Price By Week of Year')\n",
    "    plt.xticks( rotation=60 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30873667",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:40.003053Z",
     "start_time": "2023-05-17T16:38:37.675297Z"
    }
   },
   "outputs": [],
   "source": [
    "widgets.interactive(update_map, data=fixed( data ), limit=date_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4429e49f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:42.165593Z",
     "start_time": "2023-05-17T16:38:40.005049Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#51- What is the average purchase price of properties by \"Level\"?\n",
    "df=data[['Level', 'price']].groupby('Level').mean().reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd14e961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:42.170595Z",
     "start_time": "2023-05-17T16:38:42.170595Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#52- What is the average size of the living room of the properties by \"Size\"?\n",
    "   #-Size 0->Size from 0 to 1427 sqft\n",
    "   #-Size 1-> Size from 1427 to 1910 sqft\n",
    "   #-Size 2-> Size from 1910 to 2550 sqft\n",
    "   #-Size 3->Size above 2550 sqft\n",
    "\n",
    "data['Size'] = data['sqft_living'].apply(lambda x: 'Size_0' if ( x >= 0 ) & ( x <= 1427 ) else\n",
    "                                              'Size_1' if ( x > 1427 ) & ( x <= 1910 ) else\n",
    "                                              'Size_2' if ( x > 1910) & ( x <= 2550) else 'Size_3')\n",
    "df=data[['sqft_living', 'Size']]. groupby('Size').mean().reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b3d60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:42.181591Z",
     "start_time": "2023-05-17T16:38:42.181591Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c1ccdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:42.621174Z",
     "start_time": "2023-05-17T16:38:42.313130Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[139], line 23\u001B[0m\n\u001B[0;32m     20\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mprocess_time()\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m#Assigning a task to each of these \"workers\" with map function from Pool and transforming df1 from pandas to an iteration object\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m df1[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplace_ID\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mosm_type\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcountry\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcountry_code\u001B[39m\u001B[38;5;124m'\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterrows\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m#Computing the amount of time that it takes to finish the whole task\u001B[39;00m\n\u001B[0;32m     26\u001B[0m end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mprocess_time()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:367\u001B[0m, in \u001B[0;36mPool.map\u001B[1;34m(self, func, iterable, chunksize)\u001B[0m\n\u001B[0;32m    362\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, iterable, chunksize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    363\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[0;32m    364\u001B[0m \u001B[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001B[39;00m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;124;03m    in a list that is returned.\u001B[39;00m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;124;03m    '''\u001B[39;00m\n\u001B[1;32m--> 367\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapstar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:768\u001B[0m, in \u001B[0;36mApplyResult.get\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    767\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 768\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    769\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mready():\n\u001B[0;32m    770\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:765\u001B[0m, in \u001B[0;36mApplyResult.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    764\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwait\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 765\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_event\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:622\u001B[0m, in \u001B[0;36mEvent.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    620\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[0;32m    621\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[1;32m--> 622\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    623\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#53-Add the following information to the original dataset:\n",
    "   #-Place ID: Location identification\n",
    "   #-OSM Type: Open Street Map Type\n",
    "   #-Country: Country Name\n",
    "   #-Country Code: Country code\n",
    "\n",
    "#Creating my query with lat and long in a new column:\n",
    "data['query'] = data[['lat', 'long']].apply( lambda x: str( x['lat']) + ',' + str( x['long']), axis=1)\n",
    "\n",
    "#Created a file 'defs.py' with the defs function, so I need to import, because JupyterNotebook do not allow multi-threads,\n",
    "#is a sequencial tool\n",
    "import defs\n",
    "\n",
    "#Using Pool function to create 3 \"workers\"\n",
    "df1 = data[['id', 'query']]\n",
    "\n",
    "p = Pool( 4 )\n",
    "\n",
    "#Computing the amount of time that it takes to finish the whole task\n",
    "start = time.process_time()\n",
    "\n",
    "#Assigning a task to each of these \"workers\" with map function from Pool and transforming df1 from pandas to an iteration object\n",
    "df1[['place_ID', 'osm_type', 'country', 'country_code']] = p.map( defs.get_data, df1.iterrows() )\n",
    "\n",
    "#Computing the amount of time that it takes to finish the whole task\n",
    "end = time.process_time()\n",
    "print( 'Time Elapsed: {}', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e590a4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:43.717782Z",
     "start_time": "2023-05-17T16:38:43.696781Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd1453f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:45.658445Z",
     "start_time": "2023-05-17T16:38:45.646474Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import fixed\n",
    "from plotly import express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df042e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:47.234411Z",
     "start_time": "2023-05-17T16:38:47.185412Z"
    }
   },
   "outputs": [],
   "source": [
    "#54- Add the following filters to the Map:\n",
    "   #-Minimum size of the living room area\n",
    "   #-Minimum number of bathrooms\n",
    "   #-Maximum Price Value\n",
    "   #-Maximum size of basement area\n",
    "   #-Filter of Property Conditions\n",
    "   #-Filter by Year of Construction\n",
    "\n",
    "#Iterative buttons\n",
    "price_limit = widgets.IntSlider(\n",
    "                value = int(data['price'].mean()),\n",
    "                min = int(data['price'].min()),\n",
    "                max = int(data['price'].max()),\n",
    "                step = 1,\n",
    "                description = 'Maximun Price',\n",
    "                disable = False,\n",
    "                style = {'description_width': 'initial'}) \n",
    "\n",
    "livingroom_limit = widgets.IntSlider(\n",
    "                value = int( data['sqft_living'].mean()),\n",
    "                min = data['sqft_living'].min(),\n",
    "                max = data['sqft_living'].max(),\n",
    "                step = 1,\n",
    "                description = 'Minimun Living Room Area',\n",
    "                disable = False,\n",
    "                style = {'description_width': 'initial'})\n",
    "\n",
    "bathrooms_limit = widgets.IntSlider(\n",
    "                value = data['bathrooms'].mean(),\n",
    "                min = data['bathrooms'].min(),\n",
    "                max = data['bathrooms'].max(),\n",
    "                step = 1,\n",
    "                description = 'Minimun Bathrooms Number',\n",
    "                disable = False,\n",
    "                style = {'description_width': 'initial'})\n",
    "\n",
    "basement_limit = widgets.IntSlider(\n",
    "                value = int( data['sqft_basement'].mean()),\n",
    "                min = int(data['sqft_basement'].min()),\n",
    "                max = int(data['sqft_basement'].max()),\n",
    "                step = 1,\n",
    "                description = 'Maximun Basement Area',\n",
    "                disable = False,\n",
    "                style = {'description_width': 'initial'})\n",
    "\n",
    "condition_limit = widgets.IntSlider(\n",
    "                value = data['condition'].mean(),\n",
    "                min = data['condition'].min(),\n",
    "                max = data['condition'].max(),\n",
    "                step = 1,\n",
    "                description = 'House Condition',\n",
    "                disable = False,\n",
    "                style = {'description_width': 'initial'})\n",
    "\n",
    "yr_built_limit = widgets.IntSlider(\n",
    "                value = data['yr_built'].mean(),\n",
    "                min = data['yr_built'].min(),\n",
    "                max = data['yr_built'].max(),\n",
    "                step = 1,\n",
    "                description = 'Year Built',\n",
    "                disable = False,\n",
    "                style = {'description_width': 'initial'})\n",
    "\n",
    "def update_map(df, price_limit, livingroom_limit, bathrooms_limit, basement_limit, condition_limit, yr_built_limit):\n",
    "    #Filter data\n",
    "    houses = df[(df['price'] < price_limit) & (df['sqft_living'] > livingroom_limit) \n",
    "                                            & (df['bathrooms'] > bathrooms_limit )\n",
    "                                            & (df['sqft_basement'] > basement_limit )\n",
    "                                            & (df['condition'] == condition_limit )\n",
    "                                            & (df['yr_built'] == yr_built_limit )][['id', \n",
    "                                                                                       'lat', \n",
    "                                                                                       'long', \n",
    "                                                                                       'price', \n",
    "                                                                                       'sqft_living', \n",
    "                                                                                       'bathrooms',\n",
    "                                                                                       'sqft_basement',\n",
    "                                                                                       'condition',\n",
    "                                                                                       'yr_built']].copy()\n",
    "    \n",
    "    #plot map\n",
    "    fig=px.scatter_mapbox(houses, \n",
    "                     lat = 'lat',\n",
    "                     lon = 'long',\n",
    "                     size = 'price',\n",
    "                     color_continuous_scale = px.colors.cyclical.IceFire,\n",
    "                     size_max = 15,\n",
    "                     zoom = 10)\n",
    "\n",
    "    fig.update_layout( mapbox_style = 'open-street-map' )\n",
    "    fig.update_layout( height = 600, margin = {'r':0, 't':0, 'l':0, 'b':0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678393e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:38:48.492348Z",
     "start_time": "2023-05-17T16:38:48.380346Z"
    }
   },
   "outputs": [],
   "source": [
    "widgets.interactive(update_map, df=fixed(data), price_limit=price_limit, livingroom_limit=livingroom_limit, \n",
    "                    bathrooms_limit=bathrooms_limit, basement_limit=basement_limit, condition_limit=condition_limit, yr_built_limit=yr_built_limit)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54778d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T18:10:51.728576Z",
     "start_time": "2023-05-17T18:10:51.382496Z"
    }
   },
   "outputs": [],
   "source": [
    "#55- Add the following filters to the Dashboard:\n",
    "   #-Filter by date available for purchase\n",
    "   #-Filter by year of renewal\n",
    "   #-Filter if it has water view or not\n",
    "\n",
    "#Formating types to avoid erros\n",
    "data['year'] = pd.to_datetime(data['date']).dt.strftime( '%Y' )\n",
    "data['date'] = pd.to_datetime(data['date']).dt.strftime( '%Y-%m-%d' )\n",
    "data['year_week'] = pd.to_datetime(data['date']).dt.strftime( '%Y-%U' )\n",
    "\n",
    "#Filters\n",
    "date_limit = widgets.SelectionSlider(\n",
    "                options = data['date'].sort_values().unique().tolist(),\n",
    "                value ='2014-12-01',\n",
    "                description =\"Max available date\",\n",
    "                disabled=False,\n",
    "                continuous_update=False,\n",
    "                style ={'description_width':'initial'},\n",
    "                redout=True)\n",
    "\n",
    "year_limit = widgets.SelectionSlider(\n",
    "                options = data['yr_renovated'].sort_values().unique().tolist(),\n",
    "                value =2000,\n",
    "                description =\"Max year\",\n",
    "                disabled=False,\n",
    "                continuous_update=False,\n",
    "                style ={'description_width':'initial'},\n",
    "                redout=True)\n",
    "\n",
    "waterfront_limit = widgets.Checkbox(\n",
    "                value = False,\n",
    "                description=\"Waterfront?\",\n",
    "                disabled=False,\n",
    "                indent=False)\n",
    "\n",
    "def update_map( data, date_limit, year_limit, waterfront_limit):\n",
    "    #filtering data\n",
    "    df = data[(data['date'] <= date_limit)&\n",
    "             (data['yr_renovated'] >= year_limit) &\n",
    "             (data['waterfront'] == waterfront_limit)].copy()\n",
    "    fig= plt.figure(figsize=(24,12))\n",
    "    specs = gridspec.GridSpec(ncols=2, nrows=2, figure=fig)\n",
    "    \n",
    "    ax1 = fig.add_subplot(specs[0, :])\n",
    "    ax2 = fig.add_subplot(specs[1, 0])\n",
    "    ax3 = fig.add_subplot(specs[1, 1])\n",
    "    \n",
    "    #first chart\n",
    "    by_year = df[['price', 'year']].groupby( 'year').sum().reset_index()\n",
    "    sns.barplot(x='year', y='price', data=by_year, ax=ax1)\n",
    "    \n",
    "    #second chart\n",
    "    by_day = df[['price', 'date']].groupby( 'date' ).mean().reset_index()\n",
    "    sns.lineplot(x='date', y= 'price', data=by_day, ax=ax2)\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    #third chart\n",
    "    by_week_of_year = df[['price', 'year_week']].groupby('year_week').mean().reset_index()\n",
    "    sns.barplot(x='year_week', y='price', data=by_week_of_year, ax=ax3)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7105c88a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T18:10:54.261207Z",
     "start_time": "2023-05-17T18:10:51.955633Z"
    }
   },
   "outputs": [],
   "source": [
    "widgets.interactive (update_map,\n",
    "                   data = fixed( data ),\n",
    "                   date_limit=date_limit,\n",
    "                   year_limit=year_limit,\n",
    "                   waterfront_limit=waterfront_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8487f1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6265630c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80413c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
